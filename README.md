# MLT Study Group: Interactive Tools and other great Resources

# Interactive Tools

## Distill: Exploring Neural Networks with Activation Atlases

Feature inversion to visualize millions of activations from an image classification network leads to an explorable activation atlas of features the network has learned. This can reveal how the network typically represents some concepts.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/DL_study_group/blob/master/images/activation_atlas.png" width="1000"></p>](https://distill.pub/2019/activation-atlas/)


## A visual introduction to Machine Learning
Available in many different languages.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/DL_study_group/blob/master/images/intro_ML.png" width="1000"></p>](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)


## Interactive Deep Learning Playground
New to Deep Learning? Tinker with a Neural Network in your browser.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/DL_study_group/blob/master/images/dl_playground.png" width="1000"></p>](https://playground.tensorflow.org)

## Initializing neural networks

Initialization can have a significant impact on convergence in training deep neural networks. Simple initialization schemes can accelerate training, but they require care to avoid common pitfalls. In this post, deeplearning.ai folks explain how to initialize neural network parameters effectively.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/DL_study_group/blob/master/images/weight_init.png" width="1000"></p>](https://www.deeplearning.ai/ai-notes/initialization/)

# Math

## Seeing Theory: Probability and Stats

A visual introduction to probability and statistics.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/DL_study_group/blob/master/images/seeing_theory.png" width="1000"></p>](https://seeing-theory.brown.edu)

# Code

## Write a Neural Network from scratch in NumPy

The best way to understand a neural network is to code it up from scratch! 

[[Read more]](https://towardsdatascience.com/lets-code-a-neural-network-in-plain-numpy-ae7e74410795?fbclid=IwAR16PwZLqxnXE8kUUJWvu9Tmjf5OlKczRPUJENXNpuUTTz0iaKvS4Z7usa8)

[<p align="left"><img src="https://github.com/Machine-Learning-Tokyo/DL_study_group/blob/master/images/nn_from_scratch.gif" width="600"></p>](https://towardsdatascience.com/lets-code-a-neural-network-in-plain-numpy-ae7e74410795?fbclid=IwAR16PwZLqxnXE8kUUJWvu9Tmjf5OlKczRPUJENXNpuUTTz0iaKvS4Z7usa8)
